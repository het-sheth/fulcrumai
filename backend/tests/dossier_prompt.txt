#!/usr/bin/env python3
"""
Nyne Deep Research
==================
Comprehensive person intelligence by combining multiple Nyne.ai API endpoints
with LLM-powered dossier generation.

This tool aggregates data from:
1. Person Enrichment (demographics, career, social profiles, posts)
2. Person Interactions (who they follow on Twitter/X)
3. Person Article Search (press mentions, podcasts, interviews)

Then uses an LLM (Gemini, OpenAI, or Anthropic) to generate an intelligent dossier.

Usage:
    python deep_research.py --email "john@company.com"
    python deep_research.py --linkedin "https://linkedin.com/in/johndoe"
    python deep_research.py --email "john@company.com" --output dossier.md

Environment Variables Required:
    NYNE_API_KEY        - Your Nyne.ai API key
    NYNE_API_SECRET     - Your Nyne.ai API secret

    Plus ONE of the following LLM API keys (for dossier generation):
    GEMINI_API_KEY      - Google Gemini API key (recommended)
    OPENAI_API_KEY      - OpenAI API key
    ANTHROPIC_API_KEY   - Anthropic API key

Get your Nyne.ai API keys at: https://nyne.ai
"""

import argparse
import json
import os
import sys
import time
import warnings
import requests

# Suppress deprecation warning from google.generativeai
warnings.filterwarnings("ignore", category=FutureWarning, module="google.generativeai")
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional, Dict, Any
from dataclasses import dataclass

# Try to load dotenv, but don't fail if not installed
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv is optional

# ============================================================================
# CONFIGURATION
# ============================================================================

NYNE_API_KEY = os.getenv("NYNE_API_KEY")
NYNE_API_SECRET = os.getenv("NYNE_API_SECRET")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

NYNE_BASE_URL = "https://api.nyne.ai"


def check_setup():
    """Check if environment is configured and show setup instructions if not."""
    env_file_exists = os.path.exists(".env")
    has_nyne_keys = NYNE_API_KEY and NYNE_API_SECRET
    has_llm_key = GEMINI_API_KEY or OPENAI_API_KEY or ANTHROPIC_API_KEY

    if has_nyne_keys:
        return True  # All good

    # Show setup instructions
    print("""
╔══════════════════════════════════════════════════════════════════╗
║                    SETUP REQUIRED                                ║
╚══════════════════════════════════════════════════════════════════╝

Welcome to Nyne Deep Research! Before you can use this tool, you need
to configure your API keys.

STEP 1: Create your .env file
─────────────────────────────
    cp .env.example .env

STEP 2: Get your Nyne.ai API keys
─────────────────────────────────
    Visit: https://nyne.ai
    Add to .env:
        NYNE_API_KEY=your_key_here
        NYNE_API_SECRET=your_secret_here

STEP 3: Get an LLM API key (for dossier generation)
───────────────────────────────────────────────────
    Choose ONE:
    • Gemini (recommended): https://aistudio.google.com/apikey
    • OpenAI: https://platform.openai.com/api-keys
    • Anthropic: https://console.anthropic.com/

    Add to .env:
        GEMINI_API_KEY=your_key_here

STEP 4: Run again
─────────────────
    python deep_research.py --email "someone@company.com"

""")
    if not env_file_exists:
        print("    TIP: No .env file found. Run: cp .env.example .env\n")

    return False


def get_headers() -> Optional[Dict[str, str]]:
    """Get API headers with authentication. Returns None if credentials missing."""
    if not NYNE_API_KEY or not NYNE_API_SECRET:
        return None
    return {
        "X-API-Key": NYNE_API_KEY,
        "X-API-Secret": NYNE_API_SECRET,
        "Content-Type": "application/json"
    }


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class ResearchInput:
    """Input for deep research - at least one identifier required."""
    email: Optional[str] = None
    linkedin_url: Optional[str] = None
    twitter_url: Optional[str] = None
    instagram_url: Optional[str] = None
    name: Optional[str] = None
    company: Optional[str] = None


@dataclass
class ResearchResults:
    """Container for all research data."""
    enrichment: Optional[Dict] = None
    following_twitter: Optional[Dict] = None
    following_instagram: Optional[Dict] = None
    articles: Optional[Dict] = None
    errors: Optional[Dict] = None


# ============================================================================
# NYNE.AI API FUNCTIONS
# ============================================================================

def submit_enrichment(input_data: ResearchInput, headers: Dict) -> Optional[str]:
    """
    Submit person enrichment request.
    Returns request_id or None if failed.
    """
    payload = {
        "newsfeed": ["all"],
        "ai_enhanced_search": True
    }

    if input_data.email:
        payload["email"] = input_data.email
    if input_data.linkedin_url:
        payload["social_media_url"] = input_data.linkedin_url

    try:
        response = requests.post(
            f"{NYNE_BASE_URL}/person/enrichment",
            headers=headers,
            json=payload,
            timeout=30
        )
        data = response.json()
        if data.get("success") and data.get("data", {}).get("request_id"):
            return data["data"]["request_id"]
    except Exception:
        pass
    return None


def submit_following(social_url: str, headers: Dict, max_results: int = 500) -> Optional[str]:
    """
    Submit request to get who someone follows on Twitter/X or Instagram.
    Returns request_id or None if failed.

    Note: Instagram only supports 'following' type (not followers or replies).
    """
    if not social_url:
        return None

    try:
        response = requests.post(
            f"{NYNE_BASE_URL}/person/interactions",
            headers=headers,
            json={
                "type": "following",
                "social_media_url": social_url,
                "max_results": max_results
            },
            timeout=30
        )
        data = response.json()
        if data.get("success") and data.get("data", {}).get("request_id"):
            return data["data"]["request_id"]
    except Exception:
        pass
    return None


def submit_article_search(name: str, company: str, headers: Dict) -> Optional[str]:
    """
    Submit article search request.
    Returns request_id or None if failed.
    """
    if not name or not company:
        return None

    try:
        response = requests.post(
            f"{NYNE_BASE_URL}/person/articlesearch",
            headers=headers,
            json={
                "name": name,
                "company": company,
                "sort": "recent",
                "limit": 15
            },
            timeout=30
        )
        data = response.json()
        if data.get("success") and data.get("data", {}).get("request_id"):
            return data["data"]["request_id"]
    except Exception:
        pass
    return None


def poll_result(endpoint: str, request_id: str, headers: Dict,
                max_attempts: int = 60, delay: int = 5) -> Optional[Dict]:
    """
    Poll for async result.
    Returns result data or None if failed/timeout.
    """
    for _ in range(max_attempts):
        try:
            response = requests.get(
                f"{NYNE_BASE_URL}{endpoint}",
                headers=headers,
                params={"request_id": request_id},
                timeout=30
            )
            data = response.json()

            if not data.get("success"):
                return None

            result_data = data.get("data", {})
            status = result_data.get("status", "")

            if status == "completed":
                return result_data
            elif status == "failed":
                return None

            time.sleep(delay)
        except Exception:
            time.sleep(delay)

    return None


# ============================================================================
# MAIN RESEARCH FUNCTION
# ============================================================================

def deep_research(input_data: ResearchInput, verbose: bool = True) -> ResearchResults:
    """
    Execute deep research on a person using all available Nyne.ai endpoints.
    Gracefully handles missing data - never throws errors.
    """
    results = ResearchResults(errors={})
    request_ids = {}

    # Check for API credentials
    headers = get_headers()
    if not headers:
        if verbose:
            print("⚠ Missing NYNE_API_KEY or NYNE_API_SECRET")
            print("  Set these environment variables or create a .env file")
            print("  Get your API keys at: https://nyne.ai")
        return results

    if verbose:
        print("=" * 60)
        print("NYNE DEEP RESEARCH")
        print("=" * 60)

    # -------------------------------------------------------------------------
    # PHASE 1: Submit requests
    # -------------------------------------------------------------------------
    if verbose:
        print("\n[1/3] Submitting API requests...")

    # Enrichment
    req_id = submit_enrichment(input_data, headers)
    if req_id:
        request_ids["enrichment"] = req_id
        if verbose:
            print("  ✓ Enrichment request submitted")
    elif verbose:
        print("  - Enrichment: skipped (no valid input)")

    # Twitter and/or Instagram following (for psychographics)
    if input_data.twitter_url:
        req_id = submit_following(input_data.twitter_url, headers)
        if req_id:
            request_ids["following_twitter"] = req_id
            if verbose:
                print("  ✓ Twitter following request submitted")
    if input_data.instagram_url:
        req_id = submit_following(input_data.instagram_url, headers)
        if req_id:
            request_ids["following_instagram"] = req_id
            if verbose:
                print("  ✓ Instagram following request submitted")

    # Article search
    if input_data.name and input_data.company:
        req_id = submit_article_search(input_data.name, input_data.company, headers)
        if req_id:
            request_ids["articles"] = req_id
            if verbose:
                print("  ✓ Article search submitted")

    if not request_ids:
        if verbose:
            print("\n  No requests submitted. Check your input.")
        return results

    # -------------------------------------------------------------------------
    # PHASE 2: Poll for results
    # -------------------------------------------------------------------------
    if verbose:
        print(f"\n[2/3] Waiting for {len(request_ids)} API results...")

    endpoint_map = {
        "enrichment": "/person/enrichment",
        "following_twitter": "/person/interactions",
        "following_instagram": "/person/interactions",
        "articles": "/person/articlesearch"
    }

    def poll_task(key: str, req_id: str) -> tuple:
        result = poll_result(endpoint_map[key], req_id, headers)
        return key, result

    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {
            executor.submit(poll_task, key, req_id): key
            for key, req_id in request_ids.items()
        }

        for future in as_completed(futures):
            try:
                key, result = future.result()
                if result:
                    setattr(results, key, result)
                    if verbose:
                        print(f"  ✓ {key}: completed")
                elif verbose:
                    print(f"  - {key}: no data")
            except Exception:
                pass

    # -------------------------------------------------------------------------
    # PHASE 3: Extract additional data from enrichment
    # -------------------------------------------------------------------------
    if results.enrichment:
        result_data = results.enrichment.get("result", {})

        # Extract name if not provided
        if not input_data.name:
            first = result_data.get("firstname", "")
            last = result_data.get("lastname", "")
            if first and last:
                input_data.name = f"{first} {last}"

        # Extract company if not provided
        if not input_data.company:
            careers = result_data.get("careers_info", [])
            if careers:
                input_data.company = careers[0].get("company_name", "")

        # Submit article search if we now have name/company
        if input_data.name and input_data.company and "articles" not in request_ids:
            if verbose:
                print(f"\n  → Found: {input_data.name} @ {input_data.company}")
                print("  → Fetching articles...")

            req_id = submit_article_search(input_data.name, input_data.company, headers)
            if req_id:
                result = poll_result("/person/articlesearch", req_id, headers)
                if result:
                    results.articles = result
                    if verbose:
                        print("  ✓ Article search: completed")

        # Extract Twitter and Instagram from enrichment if not already provided
        social_profiles = result_data.get("social_profiles", {})

        # Try Twitter if not already fetched
        if "following_twitter" not in request_ids and not results.following_twitter:
            twitter = social_profiles.get("twitter", {})
            twitter_url = twitter.get("url")

            if twitter_url:
                if verbose:
                    print(f"  → Found Twitter: {twitter_url}")
                    print("  → Fetching following list...")

                req_id = submit_following(twitter_url, headers)
                if req_id:
                    result = poll_result("/person/interactions", req_id, headers)
                    if result:
                        results.following_twitter = result
                        if verbose:
                            print("  ✓ Following (Twitter): completed")

        # Try Instagram if not already fetched
        if "following_instagram" not in request_ids and not results.following_instagram:
            instagram = social_profiles.get("instagram", {})
            instagram_url = instagram.get("url")

            if instagram_url:
                if verbose:
                    print(f"  → Found Instagram: {instagram_url}")
                    print("  → Fetching following list...")

                req_id = submit_following(instagram_url, headers)
                if req_id:
                    result = poll_result("/person/interactions", req_id, headers)
                    if result:
                        results.following_instagram = result
                        if verbose:
                            print("  ✓ Following (Instagram): completed")

    if verbose:
        print("\n[3/3] Research complete!")
        print("=" * 60)

    return results


# ============================================================================
# LLM DOSSIER GENERATION
# ============================================================================

DOSSIER_PROMPT = '''You are an elite intelligence analyst creating the most comprehensive dossier ever written on this person. Go DEEP. Leave no stone unturned.

RULES:
1. EVERY insight MUST cite specific evidence [e.g., "follows @handle (450K followers)", "posted on Dec 15: '...'"]
2. Use EXACT quotes, dates, follower counts, company names - be obsessively specific
3. Find the "creepy good" insights - patterns that show you did real research
4. Analyze their Twitter AND Instagram following lists thoroughly - cluster accounts, find unexpected follows
5. Cross-reference their posts with who they follow to infer deeper meaning
6. Note low-follower accounts they follow - these reveal personal relationships

WRITE A DEEPLY RESEARCHED DOSSIER WITH THESE SECTIONS:

## 1. IDENTITY SNAPSHOT
Full name, nicknames, current role, company, location, age estimate, languages. Include personal details like where they live if available.

## 2. CAREER DNA
Complete career trajectory with dates. For EACH role, explain:
- What they actually did (not just title)
- Why they likely made this move
- What skills/relationships they gained
Their "superpower" - what makes them uniquely valuable

## 3. PSYCHOGRAPHIC PROFILE
Analyze their Twitter/Instagram following to understand WHO they are:
- Core archetypes (Builder, Investor, Operator, Intellectual, etc.)
- Values and motivations (inferred from follows)
- Political/social leanings (if detectable)
- CLUSTER ANALYSIS: Group the accounts they follow into categories with specific handles:
  - VCs & Investors: @handle1, @handle2...
  - Founders & Operators: ...
  - AI/Tech Researchers: ...
  - Media & Journalists: ...
  - Sports/Entertainment: ...
  - Politics/Policy: ...
  - Personal/Friends: ...

## 4. HIDDEN INTERESTS & HOBBIES
Find the UNEXPECTED follows that reveal who they are outside work:
- Sports teams, athletes they follow
- Musicians, comedians, entertainers
- Niche interests (gaming, cooking, fitness, etc.)
- Low-follower accounts (<1000) - these are often personal friends or early relationships
Be specific with handles and why each is notable.

## 5. KEY INFLUENCERS (Top 20)
The 20 most notable/influential accounts they follow:
| Handle | Name | Followers | Why They Follow Them |
For each, explain the likely relationship or reason for following.

## 6. CONTENT ANALYSIS
From their LinkedIn posts and tweets:
- Topics they post about most
- Tone and communication style
- Recent wins they've celebrated (with dates and details)
- Frustrations or complaints they've expressed
- Opinions they've stated publicly
Include EXACT QUOTES from their posts.

## 7. CONVERSATION STARTERS (20+)
Highly specific hooks based on:
- Specific posts they made (with dates)
- Unusual accounts they follow
- Career transitions
- Hidden interests
- Recent news about their company
Each starter should feel like you KNOW them.

## 8. WARNINGS & LANDMINES
- Topics that might offend them
- Competitors or people they might dislike
- Sensitive career history
- Political hot buttons to avoid

## 9. "CREEPY GOOD" INSIGHTS
The insights that make them think "how did they know that?":
- Patterns in who they follow
- Connections between their posts and follows
- Personal details buried in the data
- Things most people would miss

## 10. SUMMARY: How to Connect With This Person
A brief synthesis: what they care about, how they think, and the best angle to approach them.

---

HERE IS ALL THE RAW DATA TO ANALYZE:
{data}

Now write the most thorough dossier possible. Be exhaustive. Go deep.'''


# ============================================================================
# BATCH ANALYSIS PROMPTS
# ============================================================================

BATCH_ANALYSIS_PROMPT = '''You are a behavioral psychologist analyzing WHO someone really is based on who they follow.

PERSON CONTEXT:
Name: {person_name}
Role: {person_role}
Company: {person_company}

ANALYZE THESE {batch_size} ACCOUNTS THEY FOLLOW (Batch {batch_num} of {total_batches}):
{batch_data}

For EACH account, categorize and analyze:
1. **Category** - Be specific:
   - Professional: VC, Founder, Tech Executive, AI Researcher
   - Personal Interest: Sports (which sport?), Fitness, Food/Restaurants, Travel, Fashion, Art, Music
   - Entertainment: Comedy, Celebrities, TV Shows, Movies, Gaming
   - Hobbies: Photography, Cooking, Golf, Running, Cycling, Hiking, Cars
   - Causes: Social Justice, Climate, Politics (what leaning?), Charity
   - Personal Connection: Family member? College friend? Former colleague?

2. **What this reveals about them personally** - Go beyond the obvious:
   - Does this suggest a hobby they actively participate in?
   - A passion they might not talk about professionally?
   - A hidden side of their personality?
   - Childhood interests? Geographic ties?

3. **Personal insight** - The "getting to know them" angle:
   - Would you expect someone in their role to follow this?
   - What does this say about their personality/values?
   - How might this inform a personal conversation?

4. **Low-follower accounts** (<5000 followers) - These are GOLD for personal insights:
   - Likely personal friends, family, or niche interests
   - What does their bio reveal about the relationship?

BATCH SUMMARY:
- **Personal interests discovered** (hobbies, sports, entertainment)
- **Unexpected/surprising follows** (things you wouldn't expect)
- **Personality indicators** (introvert/extrovert, serious/playful, etc.)
- **Life outside work** (family, causes, communities)
- **Conversation hooks** for getting to know them personally (not professionally)

Focus on the HUMAN behind the professional. What makes them tick?'''

# ============================================================================
# CLUSTER ANALYSIS PROMPTS - Run in parallel for deep interest mapping
# ============================================================================

SPORTS_FITNESS_CLUSTER_PROMPT = '''You are analyzing someone's Twitter/social following list to understand their SPORTS & FITNESS interests.

PERSON: {person_name} ({person_role} at {person_company})

HERE IS EVERYONE THEY FOLLOW:
{all_following}

YOUR TASK: Find ALL sports and fitness related accounts and analyze them.

## CYCLING
List every cycling-related account they follow:
- Pro cyclists, cycling teams
- Cycling media/publications
- Local bike shops, cycling clubs
- Cycling apps (Strava, etc.)
- Cycling events/races

**Accounts Found:** [list all handles]
**Analysis:** Are they a casual rider or serious cyclist? Do they race? Road or mountain?
**Evidence-based conclusion:** "Follows X, Y, Z therefore..."

## GOLF
List every golf-related account:
- Pro golfers, PGA Tour
- Golf courses, country clubs
- Golf media, equipment brands
- Golf podcasts/personalities

**Accounts Found:** [list all handles]
**Analysis:** Do they play? What's their likely skill level? Member of clubs?

## RUNNING/MARATHON
- Running accounts, marathon organizers
- Running apps, coaches
- Track and field

**Accounts Found:** [list all handles]
**Analysis:** Casual jogger or marathon runner?

## TEAM SPORTS
### Basketball/NBA
**Accounts Found:** [list all handles]
**Analysis:** Which teams? Player or just fan?

### Football/NFL
**Accounts Found:** [list all handles]
**Analysis:** Fantasy player? Which teams?

### Baseball/MLB
**Accounts Found:** [list all handles]

### Soccer
**Accounts Found:** [list all handles]

## OTHER SPORTS
- Tennis, F1, Surfing, Skiing, etc.
**Accounts Found:** [list all handles]

## FITNESS/GYM
- Fitness influencers, gyms, trainers
- CrossFit, yoga, pilates
- Nutrition/diet accounts

**Accounts Found:** [list all handles]
**Analysis:** How fitness-focused are they?

## FINAL SPORTS PROFILE
Based on all the above, write a comprehensive sports/fitness profile:
- Which sports do they ACTIVELY PARTICIPATE in vs just watch?
- Estimated activity level (couch potato / weekend warrior / serious athlete)
- Best sports-related conversation starters
- Specific accounts to reference in conversation'''

ENTERTAINMENT_CULTURE_CLUSTER_PROMPT = '''You are analyzing someone's following list to understand their ENTERTAINMENT & CULTURE tastes.

PERSON: {person_name} ({person_role} at {person_company})

HERE IS EVERYONE THEY FOLLOW:
{all_following}

YOUR TASK: Find ALL entertainment and culture accounts and analyze their tastes.

## MUSIC
List ALL music-related accounts:
- Artists/bands they follow (list genre for each)
- Music venues, festivals
- Music industry people, labels
- Music streaming/discovery accounts
- DJs, producers

**Accounts Found:** [list all with genre]
**Music Taste Profile:** What genres? Mainstream or indie? Do they likely attend concerts?
**Conversation hooks:** Specific artists or venues to mention

## COMEDY
- Comedians they follow
- Comedy shows, podcasts
- Humor/satire accounts

**Accounts Found:** [list all handles]
**Humor Style:** Dry? Sarcastic? Political satire? Absurdist?

## TV & FILM
- Actors, directors
- TV shows, streaming services
- Film critics, movie accounts
- Entertainment news

**Accounts Found:** [list all handles]
**Viewing Habits:** What shows might they watch? Binge-watcher?

## PODCASTS
- Podcast hosts they follow
- Podcast networks
- Audio content creators

**Accounts Found:** [list all handles]
**Podcast Preferences:** Business? Comedy? True crime? Interview shows?

## BOOKS & READING
- Authors they follow
- Book reviewers, literary accounts
- Publishers, bookstores

**Accounts Found:** [list all handles]
**Reading Profile:** Fiction or non-fiction? What genres?

## FOOD & RESTAURANTS
- Chefs, restaurants
- Food critics, food media
- Cooking accounts
- Food delivery, reservation apps

**Accounts Found:** [list all handles]
**Foodie Level:** Casual eater or serious foodie? Fine dining or casual? Cuisine preferences?

## GAMING
- Game studios, esports
- Gaming personalities
- Specific games

**Accounts Found:** [list all handles]

## FINAL ENTERTAINMENT PROFILE
Comprehensive summary of their entertainment tastes:
- What do they do for fun?
- Cultural sophistication level
- Entertainment conversation starters with specific references'''

CAUSES_POLITICS_CLUSTER_PROMPT = '''You are analyzing someone's following list to understand their VALUES, CAUSES, and POLITICAL LEANINGS.

PERSON: {person_name} ({person_role} at {person_company})

HERE IS EVERYONE THEY FOLLOW:
{all_following}

YOUR TASK: Carefully analyze their follows to understand their values and political stance.

## POLITICAL FIGURES
List ALL politicians, political commentators, political organizations:

**Democrats/Liberal accounts:** [list all]
**Republicans/Conservative accounts:** [list all]
**Independent/Centrist accounts:** [list all]
**Political media they follow:** [list all]

**Political Lean Assessment:** Based on the PATTERN of follows, what is their likely political orientation?
(Be specific - not just "liberal" but "progressive Democrat" or "moderate liberal" etc.)

## SOCIAL CAUSES
### Racial Justice / Civil Rights
**Accounts Found:** [list all]
**Level of Engagement:** Casual supporter or active advocate?

### Climate / Environment
**Accounts Found:** [list all]

### LGBTQ+ Rights
**Accounts Found:** [list all]

### Women's Rights / Feminism
**Accounts Found:** [list all]

### Immigration
**Accounts Found:** [list all]

### Economic Justice / Labor
**Accounts Found:** [list all]

### Other Causes
**Accounts Found:** [list all]

## NONPROFIT / CHARITY
- Charitable organizations
- Volunteering organizations
- Philanthropic accounts

**Accounts Found:** [list all]
**Causes They Support:** What do they care about?

## RELIGIOUS / SPIRITUAL
- Religious leaders, organizations
- Spiritual accounts
- Meditation, mindfulness

**Accounts Found:** [list all]
**Spiritual Profile:** Religious? Spiritual but not religious? Secular?

## LOCAL COMMUNITY
- Local politicians
- Local news
- Community organizations
- Local businesses, events

**Accounts Found:** [list all]
**Community Engagement:** How connected are they to their local community?

## VALUES SUMMARY
Based on all the above:
- Core values they hold
- Issues they likely care deeply about
- Political conversation landmines to avoid
- Safe ways to connect on shared values'''

PERSONAL_NETWORK_CLUSTER_PROMPT = '''You are analyzing someone's following list to map their PERSONAL NETWORK and RELATIONSHIPS.

PERSON: {person_name} ({person_role} at {person_company})

HERE IS EVERYONE THEY FOLLOW:
{all_following}

YOUR TASK: Find accounts that reveal PERSONAL relationships (not just professional).

## LOW-FOLLOWER ACCOUNTS (<3000 followers)
These are likely real personal connections. For EACH one:

**Handle | Follower Count | Bio | Likely Relationship**
(List ALL accounts with <3000 followers)

For each, infer the relationship type:
- College friend (check if same school mentioned)
- Former colleague (check company mentions)
- Family member (same last name?)
- Childhood friend
- Hobby buddy
- Neighbor/local friend
- Unknown personal connection

## FORMER COLLEAGUES
Based on their career history, find people from:
- Loopt
- Shopkick
- Dropbox
- Greylock
- Script Capital/122 West
- South Park Commons

**Accounts Found from each company:** [list]

## STANFORD NETWORK
- Stanford alumni they follow
- Stanford professors, programs
- Stanford sports, organizations

**Accounts Found:** [list all]
**Stanford Involvement Level:** Casual alum or deeply connected?

## FAMILY INDICATORS
- Accounts with same last name
- "Family" or parenting accounts
- Children's content (suggests they have kids)
- Spouse/partner indicators

**Evidence of Family:** [list any evidence]
**Family Status Assessment:** Married? Kids? Close family ties?

## INNER CIRCLE
Based on interaction patterns and low-follower accounts, who are likely their closest friends?

**Probable Inner Circle:** [list 5-10 most likely close personal connections with evidence]

## RELATIONSHIP MAP SUMMARY
- Who are their real friends (not just professional contacts)?
- What communities do they belong to personally?
- Family situation insights
- Best personal connections to reference or ask about'''

HIDDEN_INTERESTS_CLUSTER_PROMPT = '''You are looking for SURPRISING and UNEXPECTED follows that reveal hidden sides of this person.

PERSON: {person_name} ({person_role} at {person_company})

HERE IS EVERYONE THEY FOLLOW:
{all_following}

YOUR TASK: Find the follows that DON'T FIT their professional profile. What do these reveal?

## UNEXPECTED FOLLOWS
List accounts that seem surprising for a {person_role}:

For each unexpected follow:
**Handle:**
**Why it's unexpected:**
**What it might reveal:**

## NICHE INTERESTS
Accounts related to very specific hobbies or interests:
- Unusual hobbies
- Niche communities
- Obscure interests

**Accounts Found:** [list all]
**What these reveal about them:**

## QUIRKY/FUN FOLLOWS
- Humor accounts
- Meme accounts
- Weird or absurdist content
- Parody accounts

**Accounts Found:** [list all]
**Sense of Humor Profile:**

## GUILTY PLEASURES
- Reality TV
- Celebrity gossip
- Pop culture they might not admit to
- "Lowbrow" entertainment

**Accounts Found:** [list all]

## BOT/UTILITY FOLLOWS
- Weather bots
- News bots
- Local alert accounts
- Utility accounts

**Accounts Found:** [list all]
**What these reveal:** (e.g., earthquake bot = cares about local SF events)

## ASPIRATIONAL FOLLOWS
Accounts they follow that suggest who they WANT to be:
- Lifestyle accounts
- Successful people in different fields
- Dream destinations, experiences

**Accounts Found:** [list all]
**Aspirational Profile:** What life do they aspire to?

## CREEPY-GOOD INSIGHTS
The most surprising discoveries that would make them think "how did you know that?":

1. [Insight with evidence]
2. [Insight with evidence]
3. [Insight with evidence]
4. [Insight with evidence]
5. [Insight with evidence]

## HIDDEN INTERESTS SUMMARY
The complete picture of who this person is BEYOND their professional identity:
- Secret hobbies
- Personality quirks
- Unexpected passions
- Things they probably don't talk about at work'''

SYNTHESIS_PROMPT = '''You are creating a COMPLETE profile of this person - not just their professional life, but WHO THEY ARE as a human being.

You have access to:
1. Their full profile/enrichment data (including social profiles like Strava, Pinterest, etc.)
2. Detailed analyses of EVERY account they follow (analyzed in batches)
3. DEEP CLUSTER ANALYSES - specialized analyses of their interests by category
4. Articles and press mentions
5. Personal details (location, family connections)

YOUR TASK: Create the most comprehensive dossier that would help someone truly KNOW this person - their passions, quirks, what makes them laugh, what they care about, who they spend time with.

## ENRICHMENT DATA (Profile, Career, Social Profiles, Posts):
{enrichment_data}

## FOLLOWING BATCH ANALYSES:
{following_analyses}

## SPORTS & FITNESS CLUSTER ANALYSIS:
{sports_cluster}

## ENTERTAINMENT & CULTURE CLUSTER ANALYSIS:
{entertainment_cluster}

## CAUSES & POLITICS CLUSTER ANALYSIS:
{causes_cluster}

## PERSONAL NETWORK CLUSTER ANALYSIS:
{network_cluster}

## HIDDEN INTERESTS CLUSTER ANALYSIS:
{hidden_cluster}

## ARTICLES & PRESS:
{articles_data}

---

Write an EXHAUSTIVE dossier with these sections:

## 1. IDENTITY SNAPSHOT
Full name, role, company, location, age estimate, birthday if available.
Personal details: location, domain names owned.
Self-description: How do they describe themselves in their bio? What does this reveal?

**Email Addresses (list ALL found):**
- Primary email
- Work emails
- Personal emails
- All alternative emails from altemails field

**Social Profiles (list ALL with URLs):**
Include every social profile found - Twitter, LinkedIn, Instagram, Strava, Pinterest, Flickr, GitHub, Foursquare, AngelList, etc.
Format as: Platform: URL

## 2. PERSONAL LIFE & HOBBIES (CRITICAL SECTION)
This is the section that makes the dossier special. Go DEEP on:

**Active Hobbies & Sports:**
- Look at their social profiles (Strava = cycling/running, Pinterest = interests, Flickr = photography)
- Sports accounts they follow - do they PLAY or just watch?
- Fitness level/activity (marathon runner? casual gym goer? golfer?)
- Weekend activities - hiking, skiing, surfing?

**Entertainment & Culture:**
- Music tastes (who do they follow? What concerts might they attend?)
- TV shows, movies, books they might enjoy
- Comedy they like (podcasts, comedians)
- Food and restaurants (any chef follows? foodie accounts?)

**Personal Passions:**
- Causes they care about (volunteering data, activist follows)
- Communities they belong to (alumni networks, local groups)
- Religious/spiritual interests
- Creative pursuits (writing, art, photography)

**Life Outside Work:**
- Family indicators (children? pets? married?)
- Where they spend time (second homes? vacation spots?)
- Friend circles (low-follower personal accounts)
- Hometown/geographic ties

**Quirks & Personality:**
- How do they describe themselves? ("lover of life's quirks")
- Sense of humor style
- Introvert or extrovert signals?
- Morning person or night owl?

## 3. CAREER DNA
Complete trajectory with dates. For EACH role:
- What they actually did
- Why they made this move
- Key relationships formed
Their "superpower" - what makes them uniquely valuable.

## 4. PSYCHOGRAPHIC PROFILE
Based on the following analyses, explain WHO this person is:
- Core identity/archetypes (The Builder? The Mentor? The Explorer?)
- Values and beliefs (with specific evidence)
- Aspirations (who do they want to be?)
- Political/social leanings (with evidence from follows)
- Professional tribes they belong to

## 5. SOCIAL GRAPH ANALYSIS (BRIEF OVERVIEW)
Quick summary of their social graph:
- **Professional Network**: VCs, founders, executives
- **Personal Interest Graph**: Sports, hobbies, entertainment
- **Inner Circle**: Low-follower accounts (likely real friends/family)

## 6. INTEREST CLUSTER DEEP DIVE (CRITICAL - BE EXHAUSTIVE)
This is the most important section. For EACH interest area, provide:
1. The specific handles they follow (list ALL relevant ones)
2. Evidence-based conclusion about their level of interest
3. Whether they're a participant or just a spectator

**FORMAT FOR EACH CLUSTER:**
```
### [INTEREST NAME]
**Accounts Followed:** @handle1, @handle2, @handle3, @handle4, @handle5...
**Evidence:** [What these follows reveal]
**Conclusion:** [Casual fan / Serious enthusiast / Active participant / Professional interest]
**Conversation Angle:** [How to use this in conversation]
```

**REQUIRED CLUSTERS TO ANALYZE (if accounts exist):**

### SPORTS & FITNESS
Break down by sport:
- **Cycling**: List ALL cycling-related follows. Are they on Strava? Do they follow pro cyclists, local bike shops, cycling media?
- **Golf**: List ALL golf follows. Country clubs? Pro golfers? Golf media?
- **Basketball/NBA**: Teams, players, analysts they follow
- **Football/NFL**: Teams, players, fantasy sports?
- **Running/Marathon**: Running accounts, race organizers?
- **Other sports**: Tennis, soccer, F1, etc.

### MUSIC & ENTERTAINMENT
- **Music**: Artists, genres, venues, music industry people. What does this say about their taste?
- **Podcasts**: Which podcast hosts/shows do they follow?
- **Comedy**: Comedians, comedy shows, humor accounts
- **TV/Film**: Actors, shows, critics, streaming services
- **Gaming**: Any gaming follows?

### FOOD & LIFESTYLE
- **Restaurants/Food**: Chefs, food critics, restaurant accounts, food media
- **Travel**: Travel accounts, destinations, airlines
- **Fashion**: Brands, designers, fashion media
- **Home/Design**: Interior design, architecture

### CAUSES & POLITICS
- **Political Figures**: Which politicians do they follow? What does the pattern suggest?
- **Social Causes**: Nonprofits, activists, social justice organizations
- **Climate/Environment**: Environmental accounts
- **Local Issues**: Local news, local politicians, community accounts

### INTELLECTUAL INTERESTS
- **Books/Reading**: Authors, book clubs, literary accounts
- **Science**: Scientists, science communicators
- **Philosophy/Spirituality**: Thinkers, spiritual leaders
- **Self-Improvement**: Productivity, habits, mental health

### TECH INTERESTS (Beyond Work)
- **Crypto/Web3**: Which projects, founders, thought leaders?
- **AI**: Beyond work - personal interest in AI?
- **Consumer Tech**: Product Hunt, gadget reviewers
- **Specific Platforms**: Deep interest in any particular platform?

### GEOGRAPHIC TIES
- **Local Community**: Local news, local businesses, local politicians
- **Hometown**: Any accounts tied to where they grew up?
- **Other Cities**: Interest in other locations?

### PERSONAL NETWORK
- **Low-Follower Accounts (<2000 followers)**: These are likely real friends, family, or niche interests
  - List each one with their bio
  - Infer the relationship (college friend? former colleague? family?)

### UNEXPECTED/SURPRISING FOLLOWS
- Accounts that don't fit their professional profile
- What do these reveal about hidden interests?

For EACH cluster, I want to see the ACTUAL HANDLES they follow as evidence.

## 7. CONTENT & VOICE ANALYSIS
From their posts:
- Topics they care about (professional AND personal)
- Communication style and tone
- Sense of humor (examples)
- Recent wins and celebrations
- Frustrations and complaints
- Strong opinions they've stated

## 8. KEY RELATIONSHIPS (Top 25)
The 25 most important accounts they follow, with:
- Handle, name, follower count
- Nature of relationship (mentor? friend? colleague? family?)
- Why this matters for understanding them

## 9. CONVERSATION STARTERS (30+)
Divide into categories:
**Professional hooks** (5-10)
**Personal interest hooks** (10-15) - hobbies, sports, entertainment
**Shared experience hooks** (5-10) - places, schools, companies
**Current events hooks** (5) - recent posts, news about them

## 10. RECOMMENDATIONS & HOW OTHERS SEE THEM
From LinkedIn recommendations:
- How do colleagues describe them?
- What qualities do people highlight?
- Any patterns in the praise?

## 11. WARNINGS & LANDMINES
- Sensitive topics to avoid
- Career sore spots (failures, missed opportunities)
- Political hot buttons
- Personal boundaries

## 12. "CREEPY GOOD" INSIGHTS
The insights that make them think "how did they know that?":
- Non-obvious patterns (e.g., follows earthquake bot = interested in SF local news)
- Cross-referenced discoveries
- Personal details most wouldn't find
- Behavioral predictions

## 13. APPROACH STRATEGY
How to connect with this person:
- Best angle (professional vs personal)
- Shared connections to mention
- Topics that will resonate
- Personal interests to reference (shows you did your homework)
- What NOT to do

This dossier should make someone feel like they already KNOW this person before ever meeting them.

CRITICAL INSTRUCTIONS:
- You MUST include ALL 13 sections listed above. Do not skip or combine sections.
- Section 6 (Interest Cluster Deep Dive) MUST include ALL subsections (Sports, Entertainment, Causes, Tech, Geographic, Personal Network, Unexpected) with SPECIFIC HANDLES as evidence.
- Key Relationships MUST list exactly 25 accounts.
- Conversation Starters MUST include 30+ hooks divided into categories.
- Be EXHAUSTIVE. This should be 400+ lines of detailed analysis.
- Do NOT summarize or condense. Include all details from the cluster analyses.'''


# ============================================================================
# LLM CALL FUNCTIONS
# ============================================================================

def _call_gemini(prompt: str) -> Optional[str]:
    """Make a single Gemini API call."""
    if not GEMINI_API_KEY:
        return None
    try:
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel(
            'gemini-3-flash-preview',
            generation_config={"temperature": 0.7, "max_output_tokens": 65536}
        )
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"    ⚠ Gemini error: {e}")
        return None


def _call_openai(prompt: str) -> Optional[str]:
    """Make a single OpenAI API call."""
    if not OPENAI_API_KEY:
        return None
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=16384
        )
        return response.choices[0].message.content
    except Exception:
        return None


def _call_anthropic(prompt: str) -> Optional[str]:
    """Make a single Anthropic API call."""
    if not ANTHROPIC_API_KEY:
        return None
    try:
        import anthropic
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=64000,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text
    except Exception:
        return None


def _get_llm_caller(llm: str = "auto"):
    """Get the appropriate LLM call function."""
    if llm == "gemini" and GEMINI_API_KEY:
        return _call_gemini, "gemini"
    elif llm == "openai" and OPENAI_API_KEY:
        return _call_openai, "openai"
    elif llm == "anthropic" and ANTHROPIC_API_KEY:
        return _call_anthropic, "anthropic"
    elif llm == "auto":
        if GEMINI_API_KEY:
            return _call_gemini, "gemini"
        elif OPENAI_API_KEY:
            return _call_openai, "openai"
        elif ANTHROPIC_API_KEY:
            return _call_anthropic, "anthropic"
    return None, None


def _batch_following_data(following_data: Dict, batch_size: int = 75) -> list:
    """Split following data into batches."""
    interactions = following_data.get("result", {}).get("interactions", [])
    if not interactions:
        return []

    batches = []
    for i in range(0, len(interactions), batch_size):
        batches.append(interactions[i:i + batch_size])
    return batches


def generate_dossier(results: ResearchResults, llm: str = "auto", verbose: bool = True) -> Optional[str]:
    """
    Generate intelligent dossier using batched LLM calls for deep analysis.

    1. Batch the following lists into chunks
    2. Run concurrent LLM calls to analyze each batch
    3. Synthesize all analyses into final dossier
    """
    # Get LLM caller
    llm_call, llm_name = _get_llm_caller(llm)
    if not llm_call:
        if verbose:
            print("  ⚠ No LLM available. Set GEMINI_API_KEY, OPENAI_API_KEY, or ANTHROPIC_API_KEY")
        return None

    if verbose:
        print(f"\n[LLM] Using {llm_name} for deep analysis...")

    # Extract person context from enrichment
    enrichment = results.enrichment or {}
    result_data = enrichment.get("result", {})
    person_name = f"{result_data.get('firstname', '')} {result_data.get('lastname', '')}".strip() or "Unknown"
    person_role = result_data.get("headline", "Unknown")
    careers = result_data.get("careers_info", [])
    person_company = careers[0].get("company_name", "Unknown") if careers else "Unknown"

    # Collect all following data
    all_following = []
    if results.following_twitter:
        twitter_interactions = results.following_twitter.get("result", {}).get("interactions", [])
        for item in twitter_interactions:
            item["_source"] = "twitter"
        all_following.extend(twitter_interactions)
    if results.following_instagram:
        ig_interactions = results.following_instagram.get("result", {}).get("interactions", [])
        for item in ig_interactions:
            item["_source"] = "instagram"
        all_following.extend(ig_interactions)

    # Batch the following data
    batch_size = 75
    batches = [all_following[i:i + batch_size] for i in range(0, len(all_following), batch_size)] if all_following else []

    following_analyses = []

    if batches:
        if verbose:
            print(f"  Analyzing {len(all_following)} followed accounts in {len(batches)} batches...")

        # Prepare batch prompts
        batch_prompts = []
        for i, batch in enumerate(batches):
            batch_data = json.dumps(batch, indent=2, default=str)
            prompt = BATCH_ANALYSIS_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                batch_size=len(batch),
                batch_num=i + 1,
                total_batches=len(batches),
                batch_data=batch_data
            )
            batch_prompts.append((i, prompt))

        # Run batch analyses concurrently
        def analyze_batch(args):
            idx, prompt = args
            return idx, llm_call(prompt)

        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(analyze_batch, bp): bp[0] for bp in batch_prompts}

            for future in as_completed(futures):
                idx, analysis = future.result()
                if analysis:
                    following_analyses.append((idx, analysis))
                    if verbose:
                        print(f"    ✓ Batch {idx + 1}/{len(batches)} analyzed")
                elif verbose:
                    print(f"    ✗ Batch {idx + 1}/{len(batches)} failed")

        # Sort by batch index
        following_analyses.sort(key=lambda x: x[0])
        following_analyses = [a[1] for a in following_analyses]

    # =========================================================================
    # PHASE 2: Deep Cluster Analysis
    # Run 5 specialized clustering prompts in parallel
    # =========================================================================

    cluster_analyses = {
        "sports": None,
        "entertainment": None,
        "causes": None,
        "network": None,
        "hidden": None
    }

    if all_following:
        if verbose:
            print(f"  Running 5 deep cluster analyses in parallel...")

        # Prepare all following data as a string for cluster prompts
        all_following_str = json.dumps(all_following, indent=2, default=str)

        # Prepare cluster prompts
        cluster_prompts = {
            "sports": SPORTS_FITNESS_CLUSTER_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                all_following=all_following_str
            ),
            "entertainment": ENTERTAINMENT_CULTURE_CLUSTER_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                all_following=all_following_str
            ),
            "causes": CAUSES_POLITICS_CLUSTER_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                all_following=all_following_str
            ),
            "network": PERSONAL_NETWORK_CLUSTER_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                all_following=all_following_str
            ),
            "hidden": HIDDEN_INTERESTS_CLUSTER_PROMPT.format(
                person_name=person_name,
                person_role=person_role,
                person_company=person_company,
                all_following=all_following_str
            )
        }

        # Run cluster analyses concurrently
        def run_cluster(args):
            cluster_name, prompt = args
            return cluster_name, llm_call(prompt)

        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(run_cluster, (name, prompt)): name
                      for name, prompt in cluster_prompts.items()}

            for future in as_completed(futures):
                cluster_name, analysis = future.result()
                if analysis:
                    cluster_analyses[cluster_name] = analysis
                    if verbose:
                        print(f"    ✓ {cluster_name.capitalize()} cluster analyzed")
                elif verbose:
                    print(f"    ✗ {cluster_name.capitalize()} cluster failed")

    # =========================================================================
    # PHASE 3: Final Synthesis
    # Combine everything into the final dossier
    # =========================================================================

    if verbose:
        print("  Synthesizing final dossier...")

    enrichment_str = json.dumps(enrichment, indent=2, default=str) if enrichment else "No enrichment data"
    following_str = "\n\n---\n\n".join(following_analyses) if following_analyses else "No following data analyzed"
    articles_str = json.dumps(results.articles, indent=2, default=str) if results.articles else "No articles found"

    synthesis_prompt = SYNTHESIS_PROMPT.format(
        enrichment_data=enrichment_str,
        following_analyses=following_str,
        sports_cluster=cluster_analyses.get("sports") or "No sports analysis available",
        entertainment_cluster=cluster_analyses.get("entertainment") or "No entertainment analysis available",
        causes_cluster=cluster_analyses.get("causes") or "No causes analysis available",
        network_cluster=cluster_analyses.get("network") or "No network analysis available",
        hidden_cluster=cluster_analyses.get("hidden") or "No hidden interests analysis available",
        articles_data=articles_str
    )

    # Generate final dossier
    dossier = llm_call(synthesis_prompt)

    if dossier and verbose:
        print("  ✓ Dossier complete!")

    return dossier


# Legacy functions for backwards compatibility
def generate_dossier_gemini(data: Dict) -> Optional[str]:
    """Legacy: Generate dossier using Google Gemini."""
    prompt = DOSSIER_PROMPT.format(data=json.dumps(data, indent=2, default=str))
    return _call_gemini(prompt)


def generate_dossier_openai(data: Dict) -> Optional[str]:
    """Legacy: Generate dossier using OpenAI."""
    prompt = DOSSIER_PROMPT.format(data=json.dumps(data, indent=2, default=str))
    return _call_openai(prompt)


def generate_dossier_anthropic(data: Dict) -> Optional[str]:
    """Legacy: Generate dossier using Anthropic Claude."""
    prompt = DOSSIER_PROMPT.format(data=json.dumps(data, indent=2, default=str))
    return _call_anthropic(prompt)


def _legacy_generate_dossier(results: ResearchResults, llm: str = "auto", verbose: bool = True) -> Optional[str]:
    """Legacy single-call dossier generation (not recommended)."""
    data = {}
    if results.enrichment:
        data["enrichment"] = results.enrichment
    if results.following_twitter:
        data["following_twitter"] = results.following_twitter
    if results.following_instagram:
        data["following_instagram"] = results.following_instagram
    if results.articles:
        data["articles"] = results.articles

    if not data:
        if verbose:
            print("\n⚠ No data available to generate dossier")
        return None

    if verbose:
        print("\n[LLM] Generating dossier...")

    # Try LLMs in order of preference
    generators = []
    if llm == "auto":
        generators = [
            ("gemini", generate_dossier_gemini),
            ("openai", generate_dossier_openai),
            ("anthropic", generate_dossier_anthropic)
        ]
    elif llm == "gemini":
        generators = [("gemini", generate_dossier_gemini)]
    elif llm == "openai":
        generators = [("openai", generate_dossier_openai)]
    elif llm == "anthropic":
        generators = [("anthropic", generate_dossier_anthropic)]

    for name, generator in generators:
        if verbose:
            print(f"  Trying {name}...")
        result = generator(data)
        if result:
            if verbose:
                print(f"  ✓ Generated with {name}")
            return result

    if verbose:
        print("  ⚠ No LLM available. Set GEMINI_API_KEY, OPENAI_API_KEY, or ANTHROPIC_API_KEY")
    return None


# ============================================================================
# CLI INTERFACE
# ============================================================================

def main():
    # Check if setup is complete
    if not check_setup():
        sys.exit(1)

    parser = argparse.ArgumentParser(
        description="Nyne Deep Research - Comprehensive person intelligence",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Best: provide both email AND LinkedIn
    python deep_research.py --email "ceo@company.com" --linkedin "https://linkedin.com/in/ceo"

    # Minimum: at least one identifier
    python deep_research.py --email "ceo@company.com"
    python deep_research.py --linkedin "https://linkedin.com/in/username"

    # Save to file
    python deep_research.py --email "ceo@company.com" --linkedin "https://linkedin.com/in/ceo" -o dossier.md

    # Raw JSON (no LLM)
    python deep_research.py --email "ceo@company.com" --json -o raw.json

Environment Variables:
    NYNE_API_KEY        Your Nyne.ai API key (required)
    NYNE_API_SECRET     Your Nyne.ai API secret (required)
    GEMINI_API_KEY      Google Gemini API key (for dossier)
    OPENAI_API_KEY      OpenAI API key (for dossier)
    ANTHROPIC_API_KEY   Anthropic API key (for dossier)

Get your Nyne.ai API keys at: https://nyne.ai
        """
    )
    parser.add_argument("--email", help="Person's email address")
    parser.add_argument("--linkedin", help="LinkedIn profile URL")
    parser.add_argument("--twitter", help="Twitter/X profile URL (for psychographics)")
    parser.add_argument("--instagram", help="Instagram profile URL (for psychographics)")
    parser.add_argument("--name", help="Person's full name (auto-extracted from enrichment)")
    parser.add_argument("--company", help="Person's company (auto-extracted from enrichment)")
    parser.add_argument("--output", "-o", help="Output file path")
    parser.add_argument("--json", action="store_true", help="Output raw JSON instead of dossier")
    parser.add_argument("--llm", choices=["gemini", "openai", "anthropic", "auto"],
                       default="auto", help="LLM for dossier (default: auto)")
    parser.add_argument("--quiet", "-q", action="store_true", help="Suppress progress output")

    args = parser.parse_args()

    if not args.email and not args.linkedin:
        parser.error("At least --email or --linkedin is required")

    input_data = ResearchInput(
        email=args.email,
        linkedin_url=args.linkedin,
        twitter_url=args.twitter,
        instagram_url=args.instagram,
        name=args.name,
        company=args.company
    )

    results = deep_research(input_data, verbose=not args.quiet)

    if args.json:
        output = json.dumps({
            "enrichment": results.enrichment,
            "following_twitter": results.following_twitter,
            "following_instagram": results.following_instagram,
            "articles": results.articles
        }, indent=2, default=str)
    else:
        output = generate_dossier(results, llm=args.llm, verbose=not args.quiet)
        if not output:
            output = "# No dossier generated\n\nEither no data was found or no LLM API key is configured."

    if args.output:
        with open(args.output, "w") as f:
            f.write(output)
        if not args.quiet:
            print(f"\nSaved to: {args.output}")
    else:
        print("\n" + output)


# ============================================================================
# PROGRAMMATIC API
# ============================================================================

def research_person(
    email: str = None,
    linkedin_url: str = None,
    twitter_url: str = None,
    instagram_url: str = None,
    name: str = None,
    company: str = None,
    generate_dossier_flag: bool = True,
    llm: str = "auto",
    verbose: bool = False
) -> Dict[str, Any]:
    """
    Programmatic API for deep research.

    Example:
        from deep_research import research_person
        result = research_person(email="ceo@startup.com")
        print(result['dossier'])
    """
    input_data = ResearchInput(
        email=email,
        linkedin_url=linkedin_url,
        twitter_url=twitter_url,
        instagram_url=instagram_url,
        name=name,
        company=company
    )

    results = deep_research(input_data, verbose=verbose)

    output = {
        "data": {
            "enrichment": results.enrichment,
            "following_twitter": results.following_twitter,
            "following_instagram": results.following_instagram,
            "articles": results.articles
        }
    }

    if generate_dossier_flag:
        output["dossier"] = generate_dossier(results, llm=llm, verbose=verbose)

    return output


if __name__ == "__main__":
    main()